{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4709b9f",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "Just predicting that there are never any cancellations at all, given that the percentage of cancelled flights is ~2.64%. This represents a naive baseline where we always predict \"no cancellation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44843d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2,400,000\n",
      "Test set size: 600,000\n",
      "\n",
      "Cancellation rate in test set: 0.0264 (2.64%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
    "\n",
    "# Load data (assuming you have a processed dataset with features)\n",
    "# If you have a processed CSV from feature engineering, load it here:\n",
    "# df = pd.read_csv(\"../data/processed_flights.csv\")\n",
    "# Otherwise, load raw data and do minimal processing:\n",
    "csv_path = \"../data/flights_sample_3m.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# For now, let's create a simple train/test split\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"CANCELLED\"])  # Features\n",
    "y = df[\"CANCELLED\"]  # Target\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train):,}\")\n",
    "print(f\"Test set size: {len(X_test):,}\")\n",
    "print(f\"\\nCancellation rate in test set: {y_test.mean():.4f} ({y_test.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5a1923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline predictions: (array([0.]), array([600000]))\n",
      "\n",
      "Actual test labels: (array([0., 1.]), array([584172,  15828]))\n"
     ]
    }
   ],
   "source": [
    "# Baseline: Predict all zeros (no cancellations)\n",
    "baseline_pred = np.zeros_like(y_test)\n",
    "\n",
    "print(f\"Baseline predictions: {np.unique(baseline_pred, return_counts=True)}\")\n",
    "print(f\"\\nActual test labels: {np.unique(y_test, return_counts=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca836f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Performance:\n",
      "  Accuracy:  0.9736\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  ROC-AUC:   0.5000\n",
      "  PR-AUC:    0.0264\n",
      "\n",
      "Confusion Matrix:\n",
      "[[584172      0]\n",
      " [ 15828      0]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate baseline performance\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_pred)\n",
    "baseline_precision = precision_score(y_test, baseline_pred, zero_division=0)\n",
    "baseline_recall = recall_score(y_test, baseline_pred, zero_division=0)\n",
    "\n",
    "# For ROC-AUC and PR-AUC, we need probability scores\n",
    "# Since baseline_pred is all zeros (binary predictions), we'll treat them as probability 0.0\n",
    "# Note: This baseline will have AUC = 0.0 because it never predicts positive class\n",
    "baseline_proba = baseline_pred.astype(float)  # Convert to float (all 0.0)\n",
    "\n",
    "try:\n",
    "    baseline_roc_auc = roc_auc_score(y_test, baseline_proba)\n",
    "except ValueError as e:\n",
    "    baseline_roc_auc = 0.0  # Will be 0.0 since no positive predictions\n",
    "    print(f\"Note: ROC-AUC calculation issue: {e}\")\n",
    "\n",
    "try:\n",
    "    baseline_pr_auc = average_precision_score(y_test, baseline_proba)\n",
    "except ValueError as e:\n",
    "    baseline_pr_auc = 0.0\n",
    "    print(f\"Note: PR-AUC calculation issue: {e}\")\n",
    "\n",
    "print(\"Baseline Model Performance:\")\n",
    "print(f\"  Accuracy:  {baseline_accuracy:.4f}\")\n",
    "print(f\"  Precision: {baseline_precision:.4f}\")\n",
    "print(f\"  Recall:    {baseline_recall:.4f}\")\n",
    "print(f\"  ROC-AUC:   {baseline_roc_auc:.4f}\")\n",
    "print(f\"  PR-AUC:    {baseline_pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, baseline_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e01521",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "- This baseline predicts **no cancellations** for all flights\n",
    "- It achieves ~97.36% accuracy (simply because most flights aren't cancelled)\n",
    "- However, it has **0% recall** (fails to catch any cancellations) and **0% precision**\n",
    "- **ROC-AUC = 0.5000**: This equals random guessing performance. When all predictions are 0.0, the ROC curve becomes a diagonal line (TPR = FPR), giving AUC = 0.5. This is the baseline for ROC-AUC (worse than random would be < 0.5)\n",
    "- **PR-AUC = 0.0264**: This equals the positive class rate (2.64% cancellation rate). When a model predicts all negatives, the PR-AUC equals the proportion of positive examples. This represents the baseline for PR-AUC\n",
    "- Any real model should beat this baseline by achieving ROC-AUC > 0.5 and PR-AUC > 0.0264\n",
    "- **Note**: For imbalanced datasets, PR-AUC is often more informative than ROC-AUC, as it focuses on the minority class performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87a5b0",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b92aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     24\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# Use 0 for unseen categories\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     X_test_processed[col] = \u001b[43mX_test_processed\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencode_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     label_encoders[col] = le\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Fill any remaining NaN values with median (for numerical) or 0\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flight-cancellations-ml/venv/lib/python3.13/site-packages/pandas/core/series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flight-cancellations-ml/venv/lib/python3.13/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flight-cancellations-ml/venv/lib/python3.13/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flight-cancellations-ml/venv/lib/python3.13/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flight-cancellations-ml/venv/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mencode_test\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_test\u001b[39m(x):\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m le.classes_:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     24\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flight-cancellations-ml/venv/lib/python3.13/site-packages/sklearn/preprocessing/_label.py:144\u001b[39m, in \u001b[36mLabelEncoder.transform\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) == \u001b[32m0\u001b[39m:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray([])\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flight-cancellations-ml/venv/lib/python3.13/site-packages/sklearn/utils/_encode.py:229\u001b[39m, in \u001b[36m_encode\u001b[39m\u001b[34m(values, uniques, check_unknown)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xp.isdtype(values.dtype, \u001b[33m\"\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flight-cancellations-ml/venv/lib/python3.13/site-packages/sklearn/utils/_encode.py:167\u001b[39m, in \u001b[36m_map_to_integer\u001b[39m\u001b[34m(values, uniques)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Map values based on its position in uniques.\"\"\"\u001b[39;00m\n\u001b[32m    166\u001b[39m xp, _ = get_namespace(values, uniques)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m table = \u001b[43m_nandict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mval\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values], device=device(values))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flight-cancellations-ml/venv/lib/python3.13/site-packages/sklearn/utils/_encode.py:154\u001b[39m, in \u001b[36m_nandict.__init__\u001b[39m\u001b[34m(self, mapping)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(mapping)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m mapping.items():\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_scalar_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    155\u001b[39m         \u001b[38;5;28mself\u001b[39m.nan_value = value\n\u001b[32m    156\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flight-cancellations-ml/venv/lib/python3.13/site-packages/sklearn/utils/_missing.py:41\u001b[39m, in \u001b[36mis_scalar_nan\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_scalar_nan\u001b[39m(x):\n\u001b[32m     10\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Test if x is NaN.\u001b[39;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[33;03m    This function is meant to overcome the issue that np.isnan does not allow\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m \u001b[33;03m    False\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumbers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIntegral\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, numbers.Real)\n\u001b[32m     43\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m math.isnan(x)\n\u001b[32m     44\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen abc>:117\u001b[39m, in \u001b[36m__instancecheck__\u001b[39m\u001b[34m(cls, instance)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Preprocessing: Handle categorical variables with label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Make a copy for preprocessing\n",
    "X_train_processed = X_train.copy()\n",
    "X_test_processed = X_test.copy()\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X_train_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Label encode categorical variables (vectorized approach for speed)\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on training data only\n",
    "    X_train_processed[col] = le.fit_transform(X_train_processed[col].astype(str))\n",
    "    \n",
    "    # Transform test data using vectorized operations\n",
    "    # Create mapping dictionary for faster lookup\n",
    "    category_to_code = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    # Use map with fillna for unseen categories (set to 0)\n",
    "    X_test_processed[col] = X_test_processed[col].astype(str).map(category_to_code).fillna(0).astype(int)\n",
    "    \n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Fill any remaining NaN values with median (for numerical) or 0\n",
    "X_train_processed = X_train_processed.fillna(X_train_processed.median())\n",
    "X_test_processed = X_test_processed.fillna(X_train_processed.median())\n",
    "\n",
    "print(f\"Processed training shape: {X_train_processed.shape}\")\n",
    "print(f\"Processed test shape: {X_test_processed.shape}\")\n",
    "print(f\"Categorical columns encoded: {categorical_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c34ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate models\n",
    "def evaluate_model(y_true, y_pred, y_proba, model_name):\n",
    "    \"\"\"Evaluate model performance and return metrics dictionary\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    pr_auc = average_precision_score(y_true, y_proba)\n",
    "    \n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'PR-AUC': pr_auc\n",
    "    }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269a59a2",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbfec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_pred = lr_model.predict(X_test_processed)\n",
    "lr_proba = lr_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "lr_results = evaluate_model(y_test, lr_pred, lr_proba, 'Logistic Regression')\n",
    "print(\"\\nLogistic Regression Performance:\")\n",
    "for metric, value in lr_results.items():\n",
    "    if metric != 'Model':\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45513d9",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Using a subset for faster training - can adjust n_estimators and remove sampling for full training\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,  # Reduce for faster training; increase for better performance\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_depth=20,  # Limit depth for faster training\n",
    "    min_samples_split=100,\n",
    "    min_samples_leaf=50\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_pred = rf_model.predict(X_test_processed)\n",
    "rf_proba = rf_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "rf_results = evaluate_model(y_test, rf_pred, rf_proba, 'Random Forest')\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "for metric, value in rf_results.items():\n",
    "    if metric != 'Model':\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556affb",
   "metadata": {},
   "source": [
    "## 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab140f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import xgboost as xgb\n",
    "    \n",
    "    # Calculate scale_pos_weight for class imbalance\n",
    "    # scale_pos_weight = number of negative samples / number of positive samples\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=100,  # Reduce for faster training\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss',\n",
    "        tree_method='hist'  # Faster training method\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    xgb_pred = xgb_model.predict(X_test_processed)\n",
    "    xgb_proba = xgb_model.predict_proba(X_test_processed)[:, 1]\n",
    "    \n",
    "    # Evaluate\n",
    "    xgb_results = evaluate_model(y_test, xgb_pred, xgb_proba, 'XGBoost')\n",
    "    print(\"\\nXGBoost Performance:\")\n",
    "    for metric, value in xgb_results.items():\n",
    "        if metric != 'Model':\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "            \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "    xgb_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c369d",
   "metadata": {},
   "source": [
    "## 4. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import lightgbm as lgb\n",
    "    \n",
    "    print(\"Training LightGBM...\")\n",
    "    \n",
    "    # Calculate scale_pos_weight for class imbalance\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,  # Reduce for faster training\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1  # Suppress output\n",
    "    )\n",
    "    \n",
    "    lgb_model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    lgb_pred = lgb_model.predict(X_test_processed)\n",
    "    lgb_proba = lgb_model.predict_proba(X_test_processed)[:, 1]\n",
    "    \n",
    "    # Evaluate\n",
    "    lgb_results = evaluate_model(y_test, lgb_pred, lgb_proba, 'LightGBM')\n",
    "    print(\"\\nLightGBM Performance:\")\n",
    "    for metric, value in lgb_results.items():\n",
    "        if metric != 'Model':\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "            \n",
    "except ImportError:\n",
    "    print(\"LightGBM not installed. Install with: pip install lightgbm\")\n",
    "    lgb_results = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7442936f",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "all_results = [lr_results, rf_results]\n",
    "\n",
    "if xgb_results:\n",
    "    all_results.append(xgb_results)\n",
    "if lgb_results:\n",
    "    all_results.append(lgb_results)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(all_results)\n",
    "comparison_df = comparison_df.set_index('Model')\n",
    "\n",
    "# Add baseline for comparison\n",
    "baseline_results = {\n",
    "    'Model': 'Baseline (All Zeros)',\n",
    "    'Accuracy': baseline_accuracy,\n",
    "    'Precision': baseline_precision,\n",
    "    'Recall': baseline_recall,\n",
    "    'ROC-AUC': baseline_roc_auc,\n",
    "    'PR-AUC': baseline_pr_auc\n",
    "}\n",
    "baseline_df = pd.DataFrame([baseline_results]).set_index('Model')\n",
    "\n",
    "# Combine baseline with model results\n",
    "comparison_df = pd.concat([baseline_df, comparison_df])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.round(4))\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Show which model performs best on each metric\n",
    "print(\"\\nBest performing models by metric:\")\n",
    "metrics_to_compare = ['Accuracy', 'Precision', 'Recall', 'ROC-AUC', 'PR-AUC']\n",
    "for metric in metrics_to_compare:\n",
    "    if metric in ['ROC-AUC', 'PR-AUC', 'Accuracy', 'Precision', 'Recall']:\n",
    "        best_idx = comparison_df[metric].idxmax()\n",
    "        best_value = comparison_df.loc[best_idx, metric]\n",
    "        print(f\"  {metric:12s}: {best_idx:20s} ({best_value:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7e2e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
